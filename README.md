# NF-FRAGMENTOMICS PIPELINE

## Introduction

Recent research indicates that analyzing the fragmentation patterns of circulating free DNA (cfDNA) from genome sequencing data can provide insights into nucleosome occupancy in the original cells. In accessible genomic regions, nucleosomes are arranged systematically to facilitate access for DNA-binding proteins.

<img src="assets/img/cfDNA_degradation.png" alt="cfDNA degradation" width="480">


## Pipeline Summary

This pipeline calculate the composite coverage over specific genome regions.

<img src="assets/img/nf-fragmentomics_base.png" alt="pipeline schema" width="480">


BAM input files are filtered by size (cfDNA fragments have size between 90 and 150 bp) and corrected for GC-bias using the method proposed by [Benjamini & Speed (2012). Nucleic Acids Research, 40(10)].

The input bam is then converted in a coverage file (bigWiggle), at this stage, it is possible to use a blackList of genomic regions. I am blacklisting the Problematic Regions of the Genome defined by ENCODE. [Amemiya, H.M., Kundaje, A. & Boyle, A.P. The ENCODE Blacklist: Identification of Problematic Regions of the Genome. Sci Rep 9, 9354 (2019). https://doi.org/10.1038/s41598-019-45839-z]

With [computeMatrix](https://deeptools.readthedocs.io/en/latest/content/tools/computeMatrix.html) we calculate the coverage of the signal (bam file) on a set of targets (bed file). In my analysis this is typically a set of Transcription Factor Binding Sites regions. We are using the `reference-point` mode: we compute the signal distribution relative to a point (the TFBS center point in our case), expanding on both sides for **4kb**.

A first plot of the composite coverage on the TFBS target set (raw coverage) is generated by the process [plotHeatmap](https://deeptools.readthedocs.io/en/latest/content/tools/plotHeatmap.html).

<img src="assets/img/plotHeatmap_example.png" alt="plotHeatmap example" width="80">

The process `PEAK_STATS` generate 3 output files:

 - `peak_data.tsv` file contains the composite coverage (`raw`) for each bin (`bin`),the coverage relative to the background median (`relative`), the background median (`background_median`) for each bin.

 - `peak_stats.csv` summary statistics for the composite coverage: signal, target, source, integration (Monte Carlo integration), length of the peak (`length`), relative length of the peak (`rlength`), mim and max raw values (`ymin` and `ymax`) and the ratio between length and integration (`ratio`)

 - `PeakIntegration.pdf` pdf plot of the calculated metrics:

<img src="assets/img/peakStats.png" alt="plotStats plot" width="480">


## Quick Start

Create a `samplesheet.csv`:

```
caseid,sampleid,timepoint,bam,bai,bw
PATIENT_A,PATIENT_A_T1,T1,/path/to/bam.bam,/path/to/bam.bai,
PATIENT_A,PATIENT_A_T2,T2,/path/to/bam.bam,/path/to/bam.bai,
```

Where: 

 - `caseid` is the patient
 - `sampleid` is the sample
 - `timepoint` is the time group
 - `bam` is the input bam file
 - `bai` is the bam index
 - `bw` is the (optional) big wiggle file (preprocessing will be skipped)


Create a target list (`targets.csv`)

```
name,source,bed
MYC,GRIFFIN,./tests/input/stub/myc.bed
ELK4,TIMON,./tests/input/stub/elk4.bed
rand1,house_keeping_dataset,./tests/input/stub/rand1.bed
rand2,house_keeping_dataset,./tests/input/stub/rand2.bed
rand3,house_keeping_dataset,./tests/input/stub/rand3.bed
HouseKeeping,house_keeping_dataset,./tests/input/stub/GeneHancer_housekeeping.bed
```

Here we are defining 6 targets: 

 - MYC and ELK4 trascription factor binding sites from GRIFFIN dataset. 
 - 3 random dataset of random genes for housekeeping plots. 
 - A set of Housekeeping genes for random comparisons.

Required parameters:

```
input: "samplesheet.csv"
targets: "targets.csv"
outdir: "./results"
```

Required annotation files and parameters (see `conf/params.config`):

 - `genome_size` : effective genome size used by GC Correction functions (see also: [deeptools effective genome size page](https://deeptools.readthedocs.io/en/latest/content/feature/effectiveGenomeSize.html))

 - `genome_2bit` : Genome in two bit format. Most genomes can be found here: http://hgdownload.cse.ucsc.edu/gbdb/

 - `blacklist_bed`: bed file with blacklisted regions used in COVERAGEBAM (wiggle file generation) and in COMPUTEMATRIX (matrix calculation). I am using the ENCODE blacklist from:
 
        Amemiya, H.M., Kundaje, A. & Boyle, A.P. The ENCODE Blacklist: Identification of Problematic Regions of the Genome. Sci Rep 9, 9354 (2019). https://doi.org/10.1038/s41598-019-45839-z


I typically put parameters in a params.yaml file and I run the pipeline with:


```
nextflow run ~/nextflow_dev/nf-fragmentomics/main.nf -params-file params.yaml
```

Available profiles (see also `conf/profiles.config`):

 - `stub`: run with stub true
 - `debug`: run with debug true
 - `devel`: run locally
 - `large`: for large bam files (Whole Genome Sequencing)
 - `small`: for small bam files (Low Pass Whole Genome Sequencing)


## Documentation

### Samplesheet specifications

We tryed the analysis with WGS and lpWGS samples.

Input bam file must be sorted and indexed. 


### Targets specifications

<!-- TODO -->

### Required Annotation files

 * Use the ENCODED blacklist or other blacklist bed file to remove problematic regions from the analysis.

### Parameters

 - `preprocess` if true the pipeline filter bam by size, apply GC correction and convert to wiggle file

 - `bin_size` the bin size used to generate the coverage file (big wiggle)

 - `target_expand_sx` and `target_expand_dx` how many bp I must expand the Target region? default is 4000 bp on both sides

 - `filter_min` and `filter_max` limit for reads filtering. By default is 90-150 bp

### Scripts

Utility scripts in `scripts` directory.

#### SampleSheet Generator

location: `scripts/samplesheet_generator.py`

```
usage: samplesheet_generator.py [-h] [-r REGEXP] [-v] [-vv] FILE [FILE ...]

Generate samplesheet.csv for nf-fragmentomics pipeline

positional arguments:
  FILE                  Bam or wiggle files

options:
  -h, --help            show this help message and exit
  -r REGEXP, --regexp REGEXP
                        Parser regexp - default: ((.*)_(.*))\..*
  -v, --verbose         set loglevel to INFO
  -vv, --very-verbose   set loglevel to DEBUG

Author: Davide Rambaldi
```

usage example with test files:

```
./scripts/samplesheet_generator.py tests/input/samplesheet_generator/*/*.{bw,bam}
```


## Analysis example

Some examples with pseudocode

### Housekeeping plots

In order to verify if in our dataset it is possible to see a signal from open chromatin regions we can do the following experiment:

1. We take all the TSS from GeneHancer
2. We calculate the composite coverage (the peak) of all TSS on Housekeeping genes (that should be always active). 
3. We then calculate the composite coverage for 100 sets of randomly picked genes NOT housekeeping

We first need to load the `peak_data.tsv` files.

Those files contains 4 columns:

 * `raw` is the raw signal
 * `bin` is the x position
 * `relative` is the signal relative to the background_median
 * `background_median` is the median calculated as shown above

In R for example we can do this:

```r
mdata <- read_delim("path/to/peak_data.tsv", show_col_types = FALSE)
```

We can load the random dataset in an object (random in the next example) and the housekeeping dataset in another object (hk in the next example). 

We can now combine the 2 data in a plot with ggplot

```r
ggplot() +
    geom_line(data = random, aes(x = bin, y = relative), color="grey", show.legend = FALSE) +
    geom_line(data = housekeeping, aes(x = bin, y = relative), color="red", show.legend = FALSE) +
    scale_x_continuous(
      "Position relative to TSS (bp)", 
      breaks = c(0,200,400,600,800), 
      labels = c("-4kb","-2kb","0","2kb","4kb")
    ) +
    ylab("Relative coverage") +
    ggtitle(plot.title) +
    scale_color_manual(values=c("grey","red")) +
    theme(legend.position = "bottom")
```

<img src="assets/img/housekeeping_plot.png" alt="HouseKeeping Genes QC Plot" width="480">


The housekeeping signal (red line in the plot) is quite different if compared to random gene sets! Do you agree?


### Target plots

Here we want to plot the composite coverage for a single Transcription Factor for a cohort across different timepoints.

We start as above from the `peak_data.tsv` files where:

 * `raw` is the raw signal
 * `bin` is the x position
 * `relative` is the signal relative to the background_median
 * `background_median` is the median calculated as shown above

In this case is better to lead the single file and merge the data in a single object:

For each peak_data file:

```r
mdata <- read_delim("path/to/peak_data.tsv", show_col_types = FALSE)
```

Mutate rdata to add sample, case and timepoint

```r
mdata <- mdata |> mutate(
    sample=sample_name,
    case=case_name,
    timepoint=timepoint_name
)
```

You can now combine different data objects in a single object using `bind_rows`.

On the final dataset we can use the `bins` on the X axis, the `relative` signal on the Y axis. We group and color observation by timepoint and we split (facet_wrap) plots by patient.

Result:

<img src="assets/img/target_plots_cdx2.png" alt="CDX2 Cohort Plot" width="480">


### Heatmaps with ComplexHeatmap

Given a set of samples and a list of targets we can build and heatmap of peak lengths or other peak statistics.

In this example we use [ComplexHeatmap](https://jokergoo.github.io/ComplexHeatmap-reference/book/index.html) and R package to draw and arrange multiple heatmaps.

<img src="assets/img/complexHeatmap_example.png" alt="ComplexHeatmap example" width="800">

<!-- TODO -->

## Credits

<!-- TODO -->

## Contributions and Support

<!-- TODO -->

## Citation

<!-- TODO -->